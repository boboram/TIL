# Redis 야무지게 사용하기 [영상](https://www.youtube.com/watch?v=92NizoBL4uA&t=1375s) 정리

## Redis Cache
- 데이터의 원래 소스보다 더 빠르고 효율적으로 액세스 할 수 있는 임시 데이터 저장소(Temporary Location For Speed)
  - 대부분의 애플리케이션에서 속도 향상을 위해 사용
  - 동일한 데이터에 대해 반복적으로 액세스하는 상황이 많을 때 사용
  - 데이터 재사용 횟수가 1번 이상이어야 의미가 있음
  - 잘 변하지 않는 데이터일 수록 효율적
- 레디스는 **캐시**로 사용하기 딱 좋음
  - 사용이 간편 : 단순한 key-value 구조
  - 모든 데이터를  메모리에 올려두는 **In-memory 데이터 저장소**(RAM)
  - 빠른 성능
    - 평균 작업속도 < 1ms
    - 초당 수백만 건의 작업 가능
- 캐싱 전략
  - 읽기 전략(읽는 작업이 많을 때) : Look-Aside(Lazy Loadking)
    - 캐시먼저 확인(Hit), 없으면 DB확인(Miss)
    - 새로 서버를 올리는 경우라면? 갑자가 Miss가 많이 발생하여 서버에 과부하가 올수도 있으므로 DB에서 미리 cache로 값을 세팅 -> **Cache Warming**
      - 상품 오픈전에 미리 DB에서 cache로 올려주는 작업을 함
  - 쓰기 전략 
    - Write-Around : DB에만 저장
      - miss가 발생한 경우에만 캐시에 저장하기 때문에 데이터가 다를 수 있다는 단점  
    - Writh-Through : 레디스, DB 저장 두단계를 해야함
      - 동일한 정보 얻을 수 있음
      - 상대적으로 느리고 데이터를 안쓰는 경우 메모리 낭비
      - 데이터 저장시 얼마만큼의 기간만 사용하겠다고 하는 expire time 지정 하는 것이 좋음 -> expire time을 어떻게 지정하느냐가 장애 포인트가 될 수 있음
## Redis 데이터 타입
- 많은 자료 구조 제공
- String : 제일 기본적, set 커맨드
  - 단순 증감 연산
  - INCR / INCRBY / INCRBYFLOAT / HINCRBY / HINCRBYFLOAT / ZINCRBY 
  - `set score:a 10` // `INCR score:a` - 11  // `INCR score:a 4` - 15
- Bitmaps : String의 변형
  - 데이터 저장공간 절약
  - 정수로 된 데이터만 카운팅 가능
  - 서비스에 오늘 접속한 유저 수? 날짜 키 만들고 유저 ID에 해당하는 비트 1로 올리기
  - `setbit visitors:20220503 3 1` // `bitcount visitors:20220503` - 2
  - 정수로 표현할 수 있어야함
- Lists : 큐(**메시지**)로 사용하기 적절
  - Blocking 기능을 이용해 Event Queue로 사용
  - 키가 있을 때만 데이터 저장 가능 - LPUSHX / RPUSHX
    - 이미 캐싱되어 있는 피드에만 신규 트윗을 저장 -> 자주 사용하는 사용자에 한해서만 저장해두기
    - SNS에서는 사용자별로 타임라인이 존재 & 본인이 팔로우한 사람들의 데이터 존재 
- Hashes : 하나의 키안에 여러개의 key-value 쌍
- Sets : 중복되지 않은 문자열의 집합
- Sorted Sets : 중복지 않은 값 저장, 모든 값은 score 순으로 정렬
- HyperLogLogs : 굉장히 많은 데이터 다룰 때 사용, 중복되지 않은 값의 개수를 카운트시 사용
  - 대용량 데이터를 카운팅시 적절(오차 0.81%)
  - set과 비슷하지만 저장되는 용량은 매우 작음(모든 값이 12KB로 고정)
  - 저장된 데이터는 다시 확인할 수 없음 -> 경우에 따라 데이터 보호를 위해 사용 가능
  - 하루 종일 크롤링한 url 개수 몇개? 검색 엔진의 유니크한 단어 몇개? -> 갯수만을 알기 위함!! 
- Streams : log를 저장하기 가장 좋은 자료 구조
  - append-only
  - 중간에 데이터가 변경 X
  - 시간 범위로 검색 / 신규 추가 데이터 수신 / 소비자별 다른 데이터 수신(소비자 그룹)
    - id 지정 안하면 시간으로 id 지정 해줌 
    - 카프카 개념 많이 차용 (카프카도 찾아보자..)
    - Streams을 메세징 브로커가 필요할때 카프카를 대체하여 사용할 수 있다고 함
## Redis 데이터 영구저장(RDB vs AOF)
### Redis는 **In-memory** 데이터 스토어 
- 서버 재시작 시 모든 데이터 유실
- 복제 기능을 사용해도 사람의 실수 발생 시 데이터 복원 불가
- Redis를 캐시 이외의 용도로 사용한다면 **적절한 데이터 백업**이 필요
### AOF (Append Only File)
- 커맨드가 들어오면 커맨드를 그대로 모두 저장(set, set, set, del 하면 4개 명령어 내역 모두 저장)
- 레디스 프로토콜 형태로 저장(읽기X)
- 저장방식
  - 자동 : redis.conf 파일에서 auto-aof-rewrite-percentage 옵션(크기 기준)
  - 수동 : BGREWRITEAOF 커맨드를 이용해 CLI 창에서 수동으로 AOF 파일 재작성
### RDB 
- 마지막 결과만 남음 
- 바이너리 파일 형태로 저장(읽기X)
- 저장방식
  - 자동 : redis.confi 파일에서 SAVE 옵션(시간 기준)
  - 수동 : BGSAVE 커맨드를 이용해 cli창에서 수동으로 RDB 파일 저장
    - SAVE 커맨드는 절대 사용X
### RDB vs AOF 선택 기준
- 백업은 필요하지만 어느 정도의 데이터 손실이 발생해도 괜찮은 경우
  - RDB 단독 사용
  - redis.conf 파일에서 SAVE 옵션을 적절히 사용 ex) SAVE 900 1
- 장애 상황 직전까지의 모든 데이터가 보장되어야 할 경우
  - AOF 사용
  - APPENDSYNC 옵션이 everysec인 경우 최대 1초 사이의 데이터 유실 가능(기본 설정)
- 제일 강력한 내구성이 필요한 경우
  - RDB & AOF 동시 사용
## 레디스 아키텍처 선택 노하우
### Replication
- master-replica
- 단순 복제 연결
  - replicaof 커맨드를 이용해 간단하게 복제 연결
  - 비동기식 복제
  - HA 기능이 없으므로 장애 상황 시 수동 복구
    - replicaof no one
    - 애플리케이션에서 연결 정보 변경
  - 모니터링X 
### Sentinel
- master-replica + sentinal(일반노드 모니터링)
- 자동 페일 오버 가능한 HA(High Availability) 구성
  - sentinel 노드가 다른 노드 감시
  - 마스터가 비정상 상태일 때 자동으로 페일 오버
  - 연결 정보 변경 필요 없음
  - sentinel 노드는 항상 **3대 이상의 홀수**로 존재해야 함 
    - 과반수 이상의 sentinel이 동의해야 페일오버 진행
### Cluster
- N대 이상의 Master-Replica 
- 스케일 아웃과 HA 구성(High Availability)
  - 키를 여러 노드에 자동으로 분할해서 저장(**샤딩**)
  - 모든 노드가 서로를 감시하여, 마스터 비정상 상태일 때 자동 페일오버
  - 최소 3대의 마스터 노드가 필요
## 아키텍처 선택 기준
<img width="418" alt="image" src="https://user-images.githubusercontent.com/14108487/166339413-64c39d0f-d761-46b1-bebf-825598813cb2.png">
(영상 이미지 참조)

- stand-alone : 마스터 한대만 띄운 형태
## Redis 운영 꿀팁과 장애 포인트
### 사용하면 안되는 커맨드
- Redis는 Single Thread 로 동작
- `keys` -> `scan` 대체 (로컬에서 사용했다가 장애시 손이 먼저나가기 때문에.. 평소에도 `scan`만 사용할 것!)
- Hash나 Sorted Set 등 자료구조
  - 키 나누기(최대 100만개이상으로는 저장하지 않는 것이 좋음)
  - 키가 많아질수록 전체 명령어 성능 떨어짐
  - `hgetall` -> `hscan`
  - `del` -> `unlink`
   - `unlink`는 백그라운드로 삭제해줌
### 변경하면 장애를 막을 수 있는 기본 설정값
- STOP-WRITES-ON-BGSAVE-ERROR = NO
  - yes(default) : RDB 파일이 정상적으로 저장되지 않았을 때 레디스로 들어오는 모든 WRITE 차단
  - 모니터링을 적절히 하고 있다면 해당 기능을 끄는 것이 좋음
  - RDB 파일 저장 실패 시 redis로의 모든 write 불가능
- MAXMEMORY-POLICY = ALLKEYS-LRU
  - redis 를 캐시로 사용할 때 Expire Time 설정 권장
  - 메모리가 가득 찼을 때 MAXMEMORY-POLICY 정책에 의해 키 관리
    - lru(Least Recently Used) : 가장 오랫동안 사용하지 않은 것부터 삭제
    - noeviction(default) : 삭제안함, 더이상 새로운 키를 저장X -> 새로운 키 저장 못하면 장애로 이어질 수 있음 
    - volatile-lru : 가장 최근에 사용X key부터 삭제 - expire 설정이 있는 key값만 삭제
    - allkeys-lru : 모든 키에 대해서 lru방식으로 삭제, 메모리가 가득차서 장애가 발생할 가능성은 없어짐
- TTL 너무 작게 설정한 경우
  - key가 만료되는 순간, 많은 서버에서 해당 key를 보고 있었다면? DB에 가서 같은 데이터를 찾는 duplicate read&write 발생 -> 굉장히 비효율적
- MaxMemory 값 설정
  - Persistence / 복제 사용시 MaxMemory 설정 주의
    - RDB 저장 & AOF rewrite 시 fork()
    - Copy-on-Write로 인해 메모리를 **두배**로 사용하는 경우 발생 가능
    - Persistence / 복제 사용시 MaxMemory는 실제 메모리의 절반으로 설정 (4GB -> 2048MB)
    - 예상치 못하게 가득 차버리는 장애가 발생할 수 있으니 두배로 설정
 - Memory 관리
   - used_memory : 논리적으로 Redis가 사용하는 메모리
   - used_memory_rss : OS가 Redis에 할당하기 위해 사용한 물리적 메모리 양
   - 삭제되는 키가 많으면 fragmentation 증가 (실제 저장양과 rss양의 차이가 큰 경우 fragmentation이 크다)
     - 특정 시점에 피크를 찍고 다시 삭제되는 경우
     - TTL로 인한 eviction(삭제)이 많이 발생하는 경우
   - CONFIG SET avtivedefrag yes : 단편화가 많이 발생하면 **잠시** 켜두면 좋음
